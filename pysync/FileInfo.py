import os
import time
import traceback

import concurrent.futures as cf

from multiprocessing import RLock
from socket import timeout
from googleapiclient.errors import HttpError, ResumableUploadError
from httplib2 import ServerNotFoundError

from pysync.Functions import SilentExit, match_attr
from pysync.OptionsParser import get_option
from pysync.Exit import exit_with_message, on_exit
from pysync.Timer import logtime
from pysync.OptionsParser import get_option


"""
This file defines a base class FileInfo and `run_drive_ops`

"""


class FileIDNotFoundError(Exception):
    pass


class GDriveQuotaExceeded(Exception):
    pass


def retry_text(_count, _max_count):
    if _max_count >= 0 and _count >= _max_count:
        return ", " + f"tried {_max_count} times, giving up" + ": "
    else:
        return ", " + f"retrying in {str(get_option('RETRY_TIME'))}s({_count}/{_max_count})" + ": "


@logtime
def run_drive_ops(diff_infos, all_data, drive):
    """Run drive_op for each push/pull operation using many threads

    Will not exceed the `Max upload threads` option

    Applies the changes to folders first, then files with least depth

    Args:
        diff_infos (list): list generated by get_diff, containing FileInfo objects
        all_data (dict): dict from get_diff
        drive (googleapiclient.discovery.Resource): Resource object from service.files() in init_drive
    """

    pending = match_attr(diff_infos, action="push") + match_attr(diff_infos, action="pull")

    pending.sort(key=lambda x: (  # * folders first, then less depth first, then alphabetitc\
        not x.isfolder, len(x.path.split("/")), x.path), reverse=True)
    # * important to sort by depth first, not just .path, contrary to other sorts for printing
    # * the items are removed(from the back), thats why its reversed
    # * sorta like a queue?

    before_paths = [i.path for i in pending]
    if pending:
        print(f"Applying {str(len(pending))} changes..")
        if not get_option("PRINT_UPLOAD"):
            print("Not showing the progress")
    else:
        print("No available changes")

    interrupt_key = "Interrupt///\\\\\\"
    failed_key = "Failed///\\\\\\"
    all_data[failed_key] = []

    max_threads = get_option("MAX_UPLOAD")
    # * must be processpool, threadpool runs into memory issue
    lock = RLock()

    # TODO it seems that the executor isn't designed to get cancelled normally
    # TODO as in it always waits when keyboard interrupt
    # TODO I might be able to do this if I don't use a `with` clause
    # TODO but when I do that I can't figure out how to submit(and wait) properly
    # TODO since there's complicated logic associated with the order of submits
    with cf.ProcessPoolExecutor(max_workers=max_threads,) as executor:

        while pending:
            index = len(pending) - 1
            if interrupt_key in all_data:
                break

            for _ in range(len(pending)):
                if interrupt_key in all_data:
                    break

                info = pending[index]
                info.find_parent(all_data)

                if not info.check_parent():
                    continue

                future = executor.submit(info.drive_op, drive, countdown=len(pending))
                pending.remove(info)

                def callback(fut):
                    exception = fut.exception()
                    if exception is not None:
                        # ? This is for catastrophic failures like running out of space,
                        # ? Where everything else must also stop
                        with lock:
                            # * test/set situation, what might happen without lock is:
                            # * thread 1 sees that there's no interrupt key
                            # * thread 2 sees that there's no interrupt key
                            # * thread 1 writes to it
                            # * thread 2 writes to it, so end result is from thread 2 but it should've been 1
                            if interrupt_key not in all_data:
                                all_data[interrupt_key] = exception
                    else:
                        info = fut.result()

                        if info.op_success:
                            if info.deletion_occured:
                                del all_data[info.path]
                            else:
                                all_data[info.path] = info
                        else:
                            # * the info gave up after retries
                            # TODO need to handle its children
                            # TODO but childrens should fail anyway maybe?
                            all_data[failed_key].append(info)

                future.add_done_callback(callback)
                index -= 1

    if interrupt_key in all_data:
        exception = all_data[interrupt_key]
        if isinstance(exception, GDriveQuotaExceeded):
            final_straw = exception.args[0]
            after_paths = [i.path for i in pending]
            done_paths = [i for i in before_paths
                          if i not in after_paths and i != final_straw]
            done_text = "\n".join(sorted(done_paths, key=lambda x: (len(x.split("/")), x)))
            exit_with_message("The following files were done before running out of space on Google drive:\n" +
                              done_text + "\n\n" +
                              f"Goole drive quota exceeded, the {str(len(done_paths))} files above were done before running out of space" +
                              "\nYour drive ran out of space while trying to upload this file: " + final_straw,
                              exception=exception)

        else:
            # * This should never happen
            exit_with_message(message="A file failed unexpectedly with the error above and other pending files were interrupted",
                              exception=exception)

    assert interrupt_key not in all_data

    if not all_data[failed_key]:
        print("All done")

    else:
        print("\nThe files below failed to sync:\n")
        for index, info in enumerate(all_data[failed_key]):
            print(str(index + 1) + ": " + info.ppath)
            print(info.failed_reason)

        on_exit(failure="some failed")
        raise SilentExit()


class FileInfo():

    """Object containing the metadata of either a local or remote file"""

    def __init__(self):

        self._action = None
        self._md5sum = None
        self.mtime = None
        self._id = None
        self._parentID = None
        self._path = None
        self._islocalgdoc = None

        self.parent = None
        self.partner = None

        self.link = None

        self.change_type = None
        self.forced = False
        self.index = None

        self.isremotegdoc = False

        self.op_attempted = False
        self.op_success = False
        self.checked_good = False

        self.failed_reason = None
        self.deletion_occured = False

    def drive_op(self, drive, countdown=None):
        """Applies the operation specified by self.change_type and self.action

        if a new remote file is a google document e.g. google sheets, google docs
        then an executable text file will be created in the local copy that opens the document in a browser

        the modification time of the local file will be set when the upload finishes
            - this is around 1 second later than what Google will say, hence the 3 seconds leeway in compare_info

        Args:
            drive (googleapiclient.discovery.Resource): Resource object from service.files() in init_drive
            countdown (int): How many operations are pending

        Raises:
            GDriveQuotaExceeded: Google drive is full, this exception will contain self.path

        """

        count = 0
        max_count = get_option("MAX_RETRY")
        if get_option("PRINT_UPLOAD") and countdown is not None:
            print(" ".join((str(countdown), self.action_human, self.ppath)))
            if countdown == 1:
                print("All jobs have been started, waiting for them to finish..")
        while True:
            try:
                self.op_checks()

                funcs = {"del remote": self.del_remote,
                         "del local": self.del_local,
                         "up new": self.up_new,
                         "down new": self.down_new,
                         "up diff": self.up_diff,
                         "down diff": self.down_diff,
                         }
                funcs[self.action_code](drive)
                break

            except Exception as exception:

                reason = traceback.format_exc() + '-' * os.get_terminal_size().columns
                if max_count >= 0 and count >= max_count:
                    self.failed_reason = reason
                    self.op_attempted = True
                    return self

                count += 1
                message = None

                if isinstance(exception, timeout):
                    message = "Timed out"

                elif isinstance(exception, ServerNotFoundError):
                    message = "Couldn't connect to server"

                elif isinstance(exception, HttpError) or isinstance(exception, ResumableUploadError):
                    if "userRateLimitExceeded" in repr(exception):
                        message = "Rate of requests too high"
                    elif "storageQuotaExceeded" in repr(exception):
                        raise GDriveQuotaExceeded(self.path)

                if message is not None:
                    print("\n" + message + retry_text(count, max_count) + self.ppath)

                else:
                    print("\nUnknown failure" + retry_text(count, max_count) +
                          self.ppath)  # + "\n" + reason)

                time.sleep(get_option("RETRY_TIME"))

        if self.action_code == "del remote" or self.action_code == "del local":
            self.deletion_occured = True

        if count > 0:
            print(f"Retry #" + str(count) + " was successful: " + self.ppath)

        self.op_success = True
        return self

    def get_action_code(self, readable):

        assert self.change_type is not None
        assert self.action is not None

        if self.action == "ignore":
            out = "ignoring" if readable else "ignore"

        elif self.change_type == "local_new":
            if self.action == "push":
                out = "uploading new" if readable else "up new"
            elif self.action == "pull":
                if self.isfolder:
                    out = "deleting local folder and ALL its content" if readable else "del local"
                else:
                    out = "deleting local file" if readable else "del local"

        elif self.change_type == "remote_new":
            if self.action == "push":
                if self.isfolder:
                    out = "deleting remote folder and ALL its content" if readable else "del remote"
                else:
                    out = "deleting remote file" if readable else "del remote"
            elif self.action == "pull":
                out = "downloading new" if readable else "down new"

        elif self.change_type == "content_change" or self.change_type == "mtime_change":
            if self.action == "push":
                out = "uploading difference" if readable else "up diff"
            elif self.action == "pull":
                out = "downloading difference" if readable else "down diff"
        else:
            raise ValueError(self.change_type + " and " + self.action + " is not valid")

        forced = "forced " if self.forced and readable else ""
        return forced + out

    def find_parent(self, all_data):

        if self.parentID is None and self.parent_path in all_data:
            self.parent = all_data[self.parent_path]  # * not exactly necessary but why not
            if isinstance(all_data[self.parent_path], str):
                self._parentID = all_data[self.parent_path]
            else:
                self._parentID = all_data[self.parent_path].id

    # def __hash__(self):

    #     out = {}
    #     for key in self.__dict__:
    #         if key == "partner":
    #             out[key] = self.partner.id
    #         item = self.__dict__[key]
    #         if isinstance(item, dict):
    #             out[key] = frozenset(item)
    #         elif isinstance(item, list):
    #             out[key] = tuple(item)
    #         else:
    #             out[key] = item

    #     return hash(frozenset(out))

    @property
    def ppath(self):
        return self.path if get_option("FULL_PATH") else self.remote_path

    @property
    def isfolder(self):
        assert self.type == "folder" or self.type == "file"
        return self.type == "folder"

    @property
    def parent_path(self):
        return os.path.split(self.path)[0]

    @property
    def isfile(self):
        return not self.isfolder

    @property
    def remote_path(self):
        """returns its path as it would appear in gdrive(without PATH in front of it)"""
        local_path = get_option("PATH")
        assert self.path is not None
        assert self.path.startswith(local_path)
        return self.path[len(local_path):]

    @property
    def action(self):
        """just to make the variable 'action' not writable"""
        return self._action

    @property
    def action_code(self):
        return self.get_action_code(False)

    @property
    def action_human(self):
        return self.get_action_code(True)

    def compare_info(self):
        raise NotImplementedError

    def op_checks(self):
        """Ran before drive_op, sets self.checked_good flag"""
        raise NotImplementedError

    def del_remote(self):
        raise NotImplementedError

    def del_local(self):
        raise NotImplementedError

    def up_new(self):
        raise NotImplementedError

    def down_new(self):
        raise NotImplementedError

    def up_diff(self):
        raise NotImplementedError

    def down_diff(self):
        raise NotImplementedError

    def calculate_md5(self):
        raise NotImplementedError

    def has_signature(self):
        raise NotImplementedError

    def gen_localgdoc(self):
        raise NotImplementedError

    def copy_remote_mtime(self):
        raise NotImplementedError

    @property
    def path(self):
        raise NotImplementedError

    @property
    def md5sum(self):
        raise NotImplementedError

    @property
    def id(self):
        raise NotImplementedError

    @property
    def islocal(self):
        raise NotImplementedError

    @property
    def isremote(self):
        raise NotImplementedError

    @property
    def isorphan(self):
        raise NotImplementedError

    @property
    def name(self):
        raise NotImplementedError

    @property
    def parentID(self):
        raise NotImplementedError

    @property
    def islocalgdoc(self):
        raise NotImplementedError

    def check_parent(self):
        return NotImplementedError

    @property
    def parentID(self):
        raise NotImplementedError

    def get_raw_local_mtime(self):
        raise NotImplementedError

    def get_iso_mtime(self):
        raise NotImplementedError
